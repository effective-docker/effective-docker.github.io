<?xml version="1.0" encoding="utf-8"?><?xml-stylesheet type="text/xml" href="http://effective-docker.github.io/feed.xslt.xml"?><feed xmlns="http://www.w3.org/2005/Atom"><generator uri="http://jekyllrb.com" version="3.1.6">Jekyll</generator><link href="http://effective-docker.github.io/feed.xml" rel="self" type="application/atom+xml" /><link href="http://effective-docker.github.io/" rel="alternate" type="text/html" /><updated>2017-01-06T22:58:31+00:00</updated><id>http://effective-docker.github.io/</id><title type="html">Effectivetrainings Blog</title><subtitle>GTechnologie zum Vorteil</subtitle><entry><title type="html">Chaos Tests</title><link href="http://effective-docker.github.io/pumba-chaos-testing/" rel="alternate" type="text/html" title="Chaos Tests" /><published>2017-01-06T00:00:00+00:00</published><updated>2017-01-06T00:00:00+00:00</updated><id>http://effective-docker.github.io/pumba-chaos-testing</id><content type="html" xml:base="http://effective-docker.github.io/pumba-chaos-testing/">&lt;div class=&quot;sect2&quot;&gt;
&lt;h3 id=&quot;chaos-testing&quot;&gt;Chaos Testing&lt;/h3&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;In verteilten Systemen können wir Fehler niemals ausschließen. Die möglichen Fehlerquellen sind fast unendlich.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;ulist&quot;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;partieller oder totaler Netzwerkausfall&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Datenbankprobleme&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Anwendungen / Services sind kurzfristig / langfristig nicht verfügbar&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Lastprobleme&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Sicherheit / Firewall / ungültige Zertifkate&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;&lt;strong&gt;Resilient Software&lt;/strong&gt; sollte so geschrieben sein, dass Fehler akzeptiert werden und der Aufrufer noch zumindest teilweise das System bedienen kann.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;&lt;strong&gt;Netflix&lt;/strong&gt; hat mit seiner Werkzeug-Box &lt;a href=&quot;https://github.com/Netflix/SimianArmy&quot;&gt;SimianArmy&lt;/a&gt; Tools für das Chaos-Testing erstellt und damit &lt;strong&gt;Chaos-Testing&lt;/strong&gt; salonfähig gemacht.
Chaos-Testing folgt den &lt;a href=&quot;http://principlesofchaos.org/&quot;&gt;Prinzipien des Chaos&lt;/a&gt;.
Beispielsweise fährt Chaos-Monkey durch Zufall ausgewählte Server-Instanzen herunter, genau wie ein Affe, der wahllos Kabel zieht.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Warum macht Netflix das? Weil nur dann sichergestellt ist, dass ein System auch dann funktioniert, wenn Upstream-Services nicht verfügbar* sind. Ein Entwickler kann sich niemals darauf verlassen, dass der Service, den er gerade aufruft auch verfügbar ist - &lt;strong&gt;Chaos&lt;/strong&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect2&quot;&gt;
&lt;h3 id=&quot;tldr&quot;&gt;TLDR;&lt;/h3&gt;
&lt;div class=&quot;ulist&quot;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Mit Pumba lassen sich Chaos-Tests in einer Docker / Swarm Umgebung ausführen.
Pumba kann:&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Container stoppen&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Pausieren&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Netzwerk Pakete verwerfen&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Netzwerk Pakete neu ordnen&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Netzwerk Pakete zurückhalten
&#39;&#39;&#39;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect2&quot;&gt;
&lt;h3 id=&quot;docker-swarm-setup&quot;&gt;Docker Swarm Setup&lt;/h3&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Zunächst setzen wir den Schwarm wie gehabt mit &lt;strong&gt;Virtual Box&lt;/strong&gt; auf, um schnellstmöglich ein einfaches Test-Szenario zu haben.
Zunächst erstellen wir uns drei Nodes.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;highlight&quot;&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;for i in {1..3}; do docker-machine create --driver virtualbox node-$i; done;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;admonitionblock tip&quot;&gt;
&lt;table&gt;
&lt;tr&gt;
&lt;td class=&quot;icon&quot;&gt;
&lt;div class=&quot;title&quot;&gt;Tip&lt;/div&gt;
&lt;/td&gt;
&lt;td class=&quot;content&quot;&gt;
Üblicherweise wird eine ungerade Anzahl an Nodes in einem Cluster verwendet. Wissen Sie warum?
&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Dann initialisieren wir den Schwarm, machen node-1 und node-2 zu &lt;strong&gt;Managern&lt;/strong&gt;, node-3 ist ein &lt;em&gt;einfacher&lt;/em&gt; &lt;strong&gt;Worker&lt;/strong&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;highlight&quot;&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;export manager=node-1
eval $(docker-machine env $manager)
docker swarm init --advertise-addr $(docker-machine ip $manager)
export token=$(docker swarm join-token -q worker)
for i in {2..3}; do
  eval $(docker-machine env node-$i)
  docker swarm join --token=$token $(docker-machine ip node-1)
done&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Wir starten wie immer den Swarm-Visualizer, um besser zu verstehen was passiert.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;highlight&quot;&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;docker service create \
  --name=viz \
  --publish=9000:8080/tcp \
  --constraint=node.role==manager \
  --mount=type=bind,src=/var/run/docker.sock,dst=/var/run/docker.sock \
  manomarks/visualizer&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;admonitionblock tip&quot;&gt;
&lt;table&gt;
&lt;tr&gt;
&lt;td class=&quot;icon&quot;&gt;
&lt;div class=&quot;title&quot;&gt;Tip&lt;/div&gt;
&lt;/td&gt;
&lt;td class=&quot;content&quot;&gt;
Die URL bekommen Sie über &#39;echo &quot;http://$(docker-machine ip $manager):9000&quot;&#39;, bei mir &lt;strong&gt;&lt;a href=&quot;http://192.168.99.100:9000&quot; class=&quot;bare&quot;&gt;http://192.168.99.100:9000&lt;/a&gt;&lt;/strong&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Im nächsten Schritt schedulen wir einige Services, die nichts weiter machen ausser sich gegenseitig aufzurufen. Das Image, dass wir hierfür verwenden ist &lt;em&gt;effectivetrainings/rest-cascade&lt;/em&gt;. Diese Image beinhaltet eine einfache Spring-Boot Anwendung mit einem Rest-Endpoint.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;highlight&quot;&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;docker network create --driver overlay test &lt;b class=&quot;conum&quot;&gt;(1)&lt;/b&gt;

# erster service
docker service create -p 8080:8080 --network test --name service-1 -e targetUri=http://service-2:8080 effectivetrainings/rest-cascade &lt;b class=&quot;conum&quot;&gt;(1)&lt;/b&gt;

for i in {2..4}; do
    docker service create --network test  --replicas=2 --name &quot;service-$i&quot; -e targetUri=http://service-$(($i+1)):8080 effectivetrainings/rest-cascade
done;

docker service create --network test --name service-5 effectivetrainings/rest-cascade &lt;b class=&quot;conum&quot;&gt;(1)&lt;/b&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;colist arabic&quot;&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Wir definieren ein Netzwerk, damit die Services im Schwarm über DNS kommunizieren können&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Über die Umgebungsvariable targetUri sagt man dem Service, dass er weitere Services aufrufen soll, wenn er angesprochen wird. Eine &lt;em&gt;Kaskade&lt;/em&gt; eben.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Der letzte Service beendet die Kaskade&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Warten wir, bis alle Services gestartet sind.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;imageblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;img src=&quot;/assets/images/chaos_testing/rest-cascade.png&quot; alt=&quot;Swarm Nodes&quot; width=&quot;800&quot;&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Der einzige Service, der von außen angesprochen werden kann ist &lt;em&gt;node-1&lt;/em&gt;, da nur dieser einen Port exposed. Der Service fungiert als unser Gateway.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Rufen wir den Service mit einem einfachen &lt;strong&gt;cURL&lt;/strong&gt; auf, sollte die Response uns sagen, welche Services in der Kommunikation beteiligt waren.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;highlight&quot;&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;curl $(docker-machine ip node-1):8080

{
  &quot;host&quot;: &quot;d6d431be03f4&quot;,
  &quot;port&quot;: 8080,
  &quot;correlationId&quot;: null,
  &quot;responseInfo&quot;: {
    &quot;host&quot;: &quot;d186a4430a59&quot;,
    &quot;port&quot;: 8080,
    &quot;correlationId&quot;: null,
    &quot;responseInfo&quot;: {
      &quot;host&quot;: &quot;aa404c0b20eb&quot;,
      &quot;port&quot;: 8080,
      &quot;correlationId&quot;: null,
      &quot;responseInfo&quot;: {
        &quot;host&quot;: &quot;9ba048210be9&quot;,
        &quot;port&quot;: 8080,
        &quot;correlationId&quot;: null,
        &quot;responseInfo&quot;: {
          &quot;host&quot;: &quot;c57154d95c3c&quot;, &lt;b class=&quot;conum&quot;&gt;(1)&lt;/b&gt;
          &quot;port&quot;: 8080,
          &quot;correlationId&quot;: null,
          &quot;responseInfo&quot;: null,
          &quot;msg&quot;: null
        },
        &quot;msg&quot;: null
      },
      &quot;msg&quot;: null
    },
    &quot;msg&quot;: null
  },
  &quot;msg&quot;: null
}&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;colist arabic&quot;&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Antworten aus Sicht des Aufrufers - in diesem Fall &lt;em&gt;service-4&lt;/em&gt; ruft &lt;em&gt;service-5&lt;/em&gt;. Die Antwort kam von Host &lt;em&gt;c57154d95c3c&lt;/em&gt;.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Zur Verifikation betrachten wir Service-5 etwas genauer.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;highlight&quot;&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;docker inspect --format {{.Status.ContainerStatus}} $(docker service ps -q service-5)
{c57154d95c3c8e3ba3954a53649c9c3d0550ad0d4ac5c64fb410a8efe7038270 7512 0}&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Hier sehen wir, service-5 arbeitet tatsächlich mit der Container-ID &lt;em&gt;c57154d95c3c8e3ba3954a53649c9c3d0550ad0d4ac5c64fb410a8efe7038270&lt;/em&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Die Service bilden also akutell folgende Kaskade.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;imageblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;img src=&quot;/assets/images/chaos_testing/kaskade.png&quot; alt=&quot;REST Kaskade&quot; width=&quot;800&quot;&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect2&quot;&gt;
&lt;h3 id=&quot;resilient-software-willkommen-im-chaos&quot;&gt;Resilient Software - Willkommen im Chaos&lt;/h3&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Was passiert, wenn wir einen Service in der Kaskade herunterfahren? Beispielsweise Node-3.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;highlight&quot;&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;docker service rm service-3&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Setzen wir anschließend erneut einen Call gegen das Gateway ab.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;highlight&quot;&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;curl $(docker-machine ip node-1):8080

{
  &quot;host&quot;: &quot;d6d431be03f4&quot;,
  &quot;port&quot;: 8080,
  &quot;correlationId&quot;: null,
  &quot;responseInfo&quot;: {
    &quot;host&quot;: &quot;65ec48cebf45&quot;,
    &quot;port&quot;: 8080,
    &quot;correlationId&quot;: null,
    &quot;responseInfo&quot;: null,
    &quot;msg&quot;: &quot;Execption: I/O error on GET request for \&quot;http://service-3:8080\&quot;: service-3; nested exception is java.net.UnknownHostException: service-3&quot;
  },
  &quot;msg&quot;: null
}%&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Die Anwendung funktioniert immer noch, zumindest &lt;em&gt;teilweise&lt;/em&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;imageblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;img src=&quot;/assets/images/chaos_testing/kaskade_fehler.png&quot; alt=&quot;REST Kaskade&quot; width=&quot;800&quot;&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Bringen wir den Service-3 wieder hoch.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;highlight&quot;&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt; docker service create --network test  --replicas=2 --name &quot;service-3&quot; -e targetUri=http://service-4:8080 effectivetrainings/rest-cascade&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect2&quot;&gt;
&lt;h3 id=&quot;pumba-chaos&quot;&gt;Pumba Chaos&lt;/h3&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Die Simian-Army von Netflix ist spezialisiert auf AWS. Im Dockerumfeld gibt es ein schönes kleines Tool namens &lt;a href=&quot;http://blog.terranillius.com/post/pumba_docker_chaos_testing/&quot;&gt;&lt;strong&gt;Pumba&lt;/strong&gt;&lt;/a&gt;, das die Chaos-Konzepte auch in die Docker-Welt bringt.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Pumba bietet hierbei ganz verschiedene Möglichkeiten, die &lt;em&gt;heile&lt;/em&gt; Welt durcheinanderzubringen.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Beispielsweise können wir Pumba anweisen, auf jedem Knoten durch Zufall irgendwelche Container herunterzufahren.
Hierfür starten wir Pumba als Task auf jedem Knoten (&lt;strong&gt;--mode global&lt;/strong&gt;) und weisen es an, Container zu stoppen (&lt;strong&gt;kill&lt;/strong&gt;)&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;highlight&quot;&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;docker service create --name pumba --mode=global  --mount=type=bind,src=/var/run/docker.sock,dst=/var/run/docker.sock gaiaadm/pumba:master pumba --random --interval 20s kill --signal SIGTERM&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Ein kleines Video dass &lt;strong&gt;Pumba vs. Swarm&lt;/strong&gt; in Aktion zeigt gibts auf Youtube.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;videoblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;iframe src=&quot;https://www.youtube.com/embed/fWUrfCtvQt8?rel=0&quot; frameborder=&quot;0&quot; allowfullscreen&gt;&lt;/iframe&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect3&quot;&gt;
&lt;h4 id=&quot;pumba-chaos-langsame-verbindung&quot;&gt;Pumba Chaos - Langsame Verbindung&lt;/h4&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Pumba kann aber noch mehr Chaos stiften. Wir haben schon simuliert, dass unsere Anwendung &lt;em&gt;so gut eben möglich&lt;/em&gt; mit Service-Ausfällen umgehen kann.
Was passiert, wenn Services beispielsweise einfach sehr lange brauchen um zu antworten? Mit Docker einfach simulierbar, indem Container pausiert werden.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Pumba kann das auch.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Um die Ergebnisse vergleichen zu können entfernen wir Pumba zunächst wieder und machen einen einfachen Load-Test gegen den &lt;em&gt;gesunden&lt;/em&gt; Cluster.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;highlight&quot;&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;eval $(docker-machine env node-1)
docker service rm pumba&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Anschließend entfernen wir alle Replicas, um später auch den Effekt von Replicas bei Timeouts zu beobachten.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;highlight&quot;&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;for i in {2..4}; do
  docker service update --replicas=1 service-$i
done;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Jetzt weisen wir Pumba an, statt Container zu stoppen, diese einfach für jeweils 3 Sekunden zu pausieren. Da wir eine Kaskade an Service Calls haben kann sich das zu einem beachtlichen Delay entwickeln.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;highlight&quot;&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;docker service create --name pumba --mode=global  --mount=type=bind,src=/var/run/docker.sock,dst=/var/run/docker.sock gaiaadm/pumba:master pumba --random --interval 5s pause --duration 3s&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Idealerweise testen wir das System direkt, indem wir es ein wenig unter Last setzen. Das geht ganz einfach mit dem Image &lt;em&gt;effectivetrainings/docker-stress&lt;/em&gt;, was intern nichts weiter nutzt als Apache Bench.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;highlight&quot;&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;docker run effectivetrainings/docker-stress -n 10000 -c 4 http://192.168.99.100:8080/ &lt;b class=&quot;conum&quot;&gt;(1)&lt;/b&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;colist arabic&quot;&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Wir feuern 10.000 Requests mit 4 Threads auf das Gateway ab.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Der Test mit 10.000 Requests dauert auf meinem Rechner ca. 1:40 Minuten. Hier das Ergebnis.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;highlight&quot;&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;Connection Times (ms)
              min  mean[+/-sd] median   max
Connect:        0   15 116.8      1    1004
Processing:     7   25  11.4     22     148
Waiting:        7   24  11.4     21     147
Total:          7   39 115.6     23    1030

Percentage of the requests served within a certain time (ms)
  50%     23
  66%     27
  75%     30
  80%     32
  90%     40
  95%     51
  98%     76
  99%   1001
 100%   1030 (longest request)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;98% der Requests wurden in weniger als 76 ms bearbeitet. 30 Requests waren auffällig langsam. Ursache unklar.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Starten wir Pumba und lassen alle 5 Sekunden einen zufälligen Container pro Host 3 Sekunden pausieren.
Die Wahrscheinlichkeit auf einen pausierten Host zu treffen ist also je nach Verteilung der Services auf die nodes recht hoch.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;highlight&quot;&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;docker service create --name pumba --mode=global  --mount=type=bind,src=/var/run/docker.sock,dst=/var/run/docker.sock gaiaadm/pumba:master pumba --random --interval 5s pause --duration 3s&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Wir lassen den Stress-Test nochmal laufen.
Nach der Verteilung der Node (3 Container pro Cluster) liegt die Wahrscheinlichkeit, einen &lt;em&gt;langsamen&lt;/em&gt; Knoten zu treffen bei 30%.
Die Wahrscheinlichkeit zwei langsame Knoten zu treffen bei ca 9% und alle drei Knoten bei rund 3%.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;admonitionblock caution&quot;&gt;
&lt;table&gt;
&lt;tr&gt;
&lt;td class=&quot;icon&quot;&gt;
&lt;div class=&quot;title&quot;&gt;Caution&lt;/div&gt;
&lt;/td&gt;
&lt;td class=&quot;content&quot;&gt;
Die Erwartung wäre also, ca. 60% der Requests sollten im Normbereich liegen, 30% der Requests durchschnittlich 3 Sekunden dauern und ein kleiner Bereich sollte sehr lange dauern (&amp;gt;= 6 Sekunden).
&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Der Testlauf braucht unglaubliche 17:49.38 Minuten.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;highlight&quot;&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;Requests per second:    9.35 [#/sec] (mean)
Time per request:       427.622 [ms] (mean)
Time per request:       106.905 [ms] (mean, across all concurrent requests)

Percentage of the requests served within a certain time (ms)
  50%     31
  66%     43
  75%     53
  80%     62
  90%     98
  95%   4795
  98%   5831
  99%   7691
 100%  12668 (longest request)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Tatsächlich sehen wir, dass immer noch 90% der Requests in weniger als 100 ms verarbeitet. 5% der Requests brauchten knapp 5 Sekunden, 1% sogar mehr als 7. der länger Request benötigt 12 Sekunden, hat also evtl. alle drei pausierten Container getroffen.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect3&quot;&gt;
&lt;h4 id=&quot;replicas&quot;&gt;Replicas&lt;/h4&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Wir wiederholen das Experiment und geben jetzt aber allen Services jeweils zwei Replicas, wir halbieren damit also die Wahrscheinlichkeit einen &lt;em&gt;langsamen&lt;/em&gt; Node zu treffen.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;highlight&quot;&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;for i in {1..5}; do
   docker service update --replicas=2 service-$i
done&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Starten wir den Stresstest erneut mit denselben Parametern.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;highlight&quot;&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;docker run effectivetrainings/docker-stress -n 10000 -c 4 http://192.168.99.100:8080/


Requests per second:    3.18 [#/sec] (mean)
Time per request:       1257.195 [ms] (mean)
Time per request:       314.299 [ms] (mean, across all concurrent requests)

Percentage of the requests served within a certain time (ms)
  50%     14
  66%     23
  75%   1069
  80%   2447
  90%   4973
  95%   7487
  98%  10007
  99%  10015
 100%  14992 (longest request)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Nur 75% der Requests konnten unter einer Sekunde ausgeführt werden, 2% (immerhin 200 Requests) brauchten mehr als 10 Sekunden für die Ausführung.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Die Erklärung dürfte im Round-Robin Loadbalancing liegen, das sich anscheinend sehr negativ auf die Performance auswirkt, rechnerisch belegen kann ich das aber nicht.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect2&quot;&gt;
&lt;h3 id=&quot;pumba-chaos-netzwerkproblem&quot;&gt;Pumba Chaos - Netzwerkproblem&lt;/h3&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Ein sehr sehr spannendes Thema ist für mich der dritte Abschnitt. Dank des &lt;em&gt;Container Network Models&lt;/em&gt; von Docker kann man sehr spannende Dinge mit dem Netzwerk machen - beispielsweise in den Traffic eingreifen.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Pumba bietet auch hierfür einige spannende Werkzeuge.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Mit &lt;a href=&quot;http://blog.terranillius.com/post/pumba_docker_chaos_testing/#network-emulation-netem-command&quot;&gt;&lt;strong&gt;pumba netem&lt;/strong&gt;&lt;/a&gt; können wir:
- Pakete verwerfen
- Pakete verzögern
- Pakete neu ordnen
- Pakete duplizieren&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Spielen wir das Experiment noch ein letztes Mal durch, starten Pumba und lassen es alle 5 Sekunden für zwei Sekunden 5% der Netzwerkpakete verwerfen.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;admonitionblock caution&quot;&gt;
&lt;table&gt;
&lt;tr&gt;
&lt;td class=&quot;icon&quot;&gt;
&lt;div class=&quot;title&quot;&gt;Caution&lt;/div&gt;
&lt;/td&gt;
&lt;td class=&quot;content&quot;&gt;
Achtung, damit das funktioniert muss das Tool &lt;em&gt;tc&lt;/em&gt; im Container installiert sein. Typischerweise kommt das mit dem Paket iproute2.
&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;highlight&quot;&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;# wieder ohne replicas
for i in {1..5}; do
   docker service update --replicas=2 service-$i
done

#remove pumba
docker service rm pumba

#restart with new configuration
docker service create --name pumba --mode=global  --mount=type=bind,src=/var/run/docker.sock,dst=/var/run/docker.sock gaiaadm/pumba:master pumba --debug --random --interval 5s netem --duration 2s loss --percent 5&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Ich kann nicht abschätzen, ob das überhaupt irgendwelche Auswirkungen haben wird. Starten wir den Stresstest erneut und vergleichen mit der ursprünglichen Annahme.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;highlight&quot;&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;docker run effectivetrainings/docker-stress -n 10000 -c 4 http://192.168.99.100:8080/

Time per request:       82.795 [ms] (mean)
Time per request:       20.699 [ms] (mean, across all concurrent requests)

Percentage of the requests served within a certain time (ms)
  50%     23
  66%     30
  75%     35
  80%     40
  90%     54
  95%     76
  98%    243
  99%   1014
 100%  10225 (longest request)

Complete requests:      10000
Failed requests:        3880&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Der Testlauf dauerte ca. 3:40min.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Starten wir Pumba erneut aber diesmal mit 50% Loss.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;highlight&quot;&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;#remove pumba
docker service rm pumba

#restart with new configuration
docker service create --name pumba --mode=global  --mount=type=bind,src=/var/run/docker.sock,dst=/var/run/docker.sock gaiaadm/pumba:master pumba --debug --random --interval 5s netem --duration 2s loss --percent 50

docker run effectivetrainings/docker-stress -n 10000 -c 4 http://192.168.99.100:8080/

Complete requests:      10000
Failed requests:        9329 &lt;b class=&quot;conum&quot;&gt;(1)&lt;/b&gt;
   (Connect: 0, Receive: 0, Length: 9329, Exceptions: 0)

Percentage of the requests served within a certain time (ms)
  50%     18
  66%     25
  75%     32
  80%     37
  90%     58
  95%     98
  98%   1018
  99%   3006
 100%  12490 (longest request)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Die Fehlerrate ist verheerend&lt;/p&gt;
&lt;/div&gt;
&lt;hr&gt;
&lt;div class=&quot;sect3&quot;&gt;
&lt;h4 id=&quot;fazit&quot;&gt;Fazit&lt;/h4&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Chaos-Testing macht Spaß. Mit &lt;strong&gt;Pumba&lt;/strong&gt; lassen sich erstaunliche Dinge machen.
Stress-Testing / Chaos-Testing macht definitiv Sinn. Ich würde es wahrscheinlich nicht in Produktion machen - wohl aber beispielsweise auf einer Testumgebung.&lt;/p&gt;
&lt;/div&gt;
&lt;hr&gt;
&lt;/div&gt;
&lt;div class=&quot;sect3&quot;&gt;
&lt;h4 id=&quot;links&quot;&gt;Links&lt;/h4&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;&lt;a href=&quot;https://hub.docker.com/r/effectivetrainings/rest-cascade/&quot;&gt;Rest Kaskade Docker Image&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;&lt;a href=&quot;https://hub.docker.com/r/effectivetrainings/docker-stress/&quot;&gt;docker stress test image&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;hr&gt;
&lt;/div&gt;
&lt;div class=&quot;sect3&quot;&gt;
&lt;h4 id=&quot;cleanup&quot;&gt;Cleanup&lt;/h4&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Damit ist das Experiment beendet und wir verwischen alle Spuren.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;highlight&quot;&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;docker service rm pumba

for i in {1..5}; do
   docker service rm service-$i
done

docker service rm viz

docker network rm test

docker-machine rm node-1 node-2 node-3&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect3&quot;&gt;
&lt;h4 id=&quot;docker-training&quot;&gt;Docker Training&lt;/h4&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;&lt;strong&gt;Wollen Sie mehr erfahren?&lt;/strong&gt;
Ich biete &lt;a href=&quot;http://www.effectivetrainings.de/html/workshops/effective_docker_workshop.php&quot;&gt;Consulting / Training&lt;/a&gt; für Docker. Schauen Sie doch mal vorbei!&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</content><summary type="html">Chaos Testing

In verteilten Systemen können wir Fehler niemals ausschließen. Die möglichen Fehlerquellen sind fast unendlich.




partieller oder totaler Netzwerkausfall


Datenbankprobleme


Anwendungen / Services sind kurzfristig / langfristig nicht verfügbar


Lastprobleme


Sicherheit / Firewall / ungültige Zertifkate




Resilient Software sollte so geschrieben sein, dass Fehler akzeptiert werden und der Aufrufer noch zumindest teilweise das System bedienen kann.


Netflix hat mit seiner Werkzeug-Box SimianArmy Tools für das Chaos-Testing erstellt und damit Chaos-Testing salonfähig gemacht.
Chaos-Testing folgt den Prinzipien des Chaos.
Beispielsweise fährt Chaos-Monkey durch Zufall ausgewählte Server-Instanzen herunter, genau wie ein Affe, der wahllos Kabel zieht.


Warum macht Netflix das? Weil nur dann sichergestellt ist, dass ein System auch dann funktioniert, wenn Upstream-Services nicht verfügbar* sind. Ein Entwickler kann sich niemals darauf verlassen, dass der Service, den er gerade aufruft auch verfügbar ist - Chaos.</summary></entry><entry><title type="html">Docker Swarm Health Checks</title><link href="http://effective-docker.github.io/docker-swarm-health-checks/" rel="alternate" type="text/html" title="Docker Swarm Health Checks" /><published>2017-01-04T00:00:00+00:00</published><updated>2017-01-04T00:00:00+00:00</updated><id>http://effective-docker.github.io/docker-swarm-health-checks</id><content type="html" xml:base="http://effective-docker.github.io/docker-swarm-health-checks/">&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;docker-swarm-mode-health-checks&quot;&gt;Docker Swarm Mode Health Checks&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;sect2&quot;&gt;
&lt;h3 id=&quot;tldr&quot;&gt;TLDR;&lt;/h3&gt;
&lt;div class=&quot;ulist&quot;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Die Sourcen sind unter : &lt;a href=&quot;https://github.com/effective-docker/docker-healthcheck.git&quot; class=&quot;bare&quot;&gt;https://github.com/effective-docker/docker-healthcheck.git&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Swarm Scheduler arbeitet mit den Container Health Checks&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Nur &lt;em&gt;healthy&lt;/em&gt; Container werden geroutet.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Nach drei fehlgeschlagenen Health-Checks wird ein Container neu gestartet (ggf. auch auf einem anderen Knoten)&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;hr&gt;
&lt;/div&gt;
&lt;div class=&quot;sect2&quot;&gt;
&lt;h3 id=&quot;docker-swarm-mode&quot;&gt;Docker Swarm Mode&lt;/h3&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Im &lt;a href=&quot;https://effective-docker.github.io/docker-healthchecks/&quot;&gt;letzten Eintrag&lt;/a&gt; haben wir uns mit &lt;em&gt;Health Checks&lt;/em&gt; in Containern beschäftigt. Das alleine ist schon eine sehr wichtige Funktionalität, entwickelt ihr Potential allerdings erst in Zusammenarbeit mit einem Scheduler der das aktiv unterstützt. In diesem Artikel konzentrieren wir uns auf &lt;strong&gt;Docker Swarm im Swarm Mode (ab 1.12)&lt;/strong&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Swarm Mode ist das &lt;em&gt;neue&lt;/em&gt; Swarm integriert in die Docker Engine - &lt;em&gt;nicht zu verwechseln&lt;/em&gt; mit &lt;a href=&quot;https://docs.docker.com/swarm/overview/&quot;&gt;Docker Swarm (Standalone)&lt;/a&gt;, was vor 1.12 aktuell war.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Im folgenden arbeiten wir der Einfachheit halber mit VirtualBox und Docker-Machine.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Zunächst setzen erstellen wir uns einen Stack mit 3 Nodes.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;admonitionblock tip&quot;&gt;
&lt;table&gt;
&lt;tr&gt;
&lt;td class=&quot;icon&quot;&gt;
&lt;div class=&quot;title&quot;&gt;Tipp&lt;/div&gt;
&lt;/td&gt;
&lt;td class=&quot;content&quot;&gt;
Die Anzahl an Nodes im Schwarm sollte nach Möglichkeit ungerade sein, damit man einfache Mehrheiten bilden kann.
&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;highlight&quot;&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;for i in {1..3}; do
    docker-machine create --driver=virtualbox swarm-node-$i
done&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;admonitionblock tip&quot;&gt;
&lt;table&gt;
&lt;tr&gt;
&lt;td class=&quot;icon&quot;&gt;
&lt;div class=&quot;title&quot;&gt;Tipp&lt;/div&gt;
&lt;/td&gt;
&lt;td class=&quot;content&quot;&gt;
Wenn wir die Maschinen mit &lt;em&gt;docker-machine&lt;/em&gt; erstellen sind bereits alle Zertifikate richtig konfiguriert.
&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Zunächst prüfen wir, ob die Knoten korrekt erstellt und gestartet sind.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;highlight&quot;&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;docker-machine ls
swarm-node-1      -        virtualbox   Running   tcp://192.168.99.101:2376
swarm-node-2      -        virtualbox   Running   tcp://192.168.99.102:2376
swarm-node-3      -        virtualbox   Running   tcp://192.168.99.103:2376&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Mit den einzelnen Knoten können wir uns jetzt über die &lt;em&gt;Docker Remote&lt;/em&gt;-API verbinden.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Wir machen die Knoten 1 und 2 zu &lt;em&gt;Swarm-Managern&lt;/em&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;highlight&quot;&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;#connect to node 1
eval $(docker-machine env swarm-node-1)

docker swarm init --advertise-addr $(docker-machine ip swarm-node-1)

# connect to node 2
eval $(docker-machine env swarm-node-2) &lt;b class=&quot;conum&quot;&gt;(1)&lt;/b&gt;


# join swarm as worker
docker swarm join --token &amp;lt;token&amp;gt; $(docker-machine ip swarm-node-1):2377 &lt;b class=&quot;conum&quot;&gt;(2)&lt;/b&gt;

# connect to node 3
eval $(docker-machine env swarm-node-3)

# join swarm as worker
docker swarm join --token &amp;lt;token&amp;gt; $(docker-machine ip swarm-node-1):2377 &lt;b class=&quot;conum&quot;&gt;(3)&lt;/b&gt;

# promote node-2
docker node promote swarm-node-2
Node swarm-node-2 promoted to a manager in the swarm. &lt;b class=&quot;conum&quot;&gt;(4)&lt;/b&gt;


# status
docker node ls
ID                           HOSTNAME      STATUS  AVAILABILITY  MANAGER STATUS
kr5m52gdhx3ky7enck5ifjd27    swarm-node-2  Ready   Active        Reachable
qb2llmor6n5hogv3ql1pudl7d *  swarm-node-1  Ready   Active        Leader
wr708u31k6uxogn0u66ykh61n    swarm-node-3  Ready   Active&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;hr&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Die Kommunikation im Swarm muss immer über einen Manager geschehen, denn nur Manager haben die Befugnis &lt;em&gt;Entscheidungen&lt;/em&gt; treffen.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;sect2&quot;&gt;
&lt;h3 id=&quot;beispielanwendung&quot;&gt;Beispielanwendung&lt;/h3&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Wir arbeiten erneut mit der &lt;em&gt;einfachen&lt;/em&gt; Health-Check Spring Boot Applikation aus dem letzten Artikel.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Zusätzlich deployen wir den &lt;a href=&quot;https://github.com/ManoMarks/docker-swarm-visualizer&quot;&gt;Swarm-Visualizer&lt;/a&gt; um den Schwarm zu sichtbar zu machen.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;highlight&quot;&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;docker service create \
  --name=viz \
  --publish=9000:8080/tcp \
  --constraint=node.role==manager \ &lt;b class=&quot;conum&quot;&gt;(1)&lt;/b&gt;
  --mount=type=bind,src=/var/run/docker.sock,dst=/var/run/docker.sock \
  manomarks/visualizer&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;colist arabic&quot;&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Der Visualizer &lt;strong&gt;muss&lt;/strong&gt; auf einem Manager laufen&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Prüfen Sie mit &lt;em&gt;docker service ls&lt;/em&gt; wann der Visualizer bereit ist.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;highlight&quot;&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;docker service ls
mbkr330h65kh  viz   replicated  0/1       manomarks/visualizer:latest&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;imageblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;img src=&quot;/assets/images/swarm_health/swarm_visualizer.png&quot; alt=&quot;Swarm Visualizer&quot; width=&quot;600&quot;&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Deployen Sie anschließend die Health-Applikation als Service mit zwei Replicas.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;highlight&quot;&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;#connect to manager
eval $(docker-machine env swarm-node-1)

docker service create --health-cmd &quot;curl -f http://localhost:8080/health || exit 1&quot; --name health --replicas 2 -p 8080:8080 effectivetrainings/docker-health

#status
docker service ps viz
ID         NAME   IMAGE                        NODE          DESIRED STATE CURRENT STATE
ymzuujcd6awr  viz.1  manomarks/visualizer:latest  swarm-node-1  Running        Preparing&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;imageblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;img src=&quot;/assets/images/swarm_health/swarm_replicas.png&quot; alt=&quot;Swarm Replicas&quot; width=&quot;600&quot;&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;hr&gt;
&lt;/div&gt;
&lt;div class=&quot;sect2&quot;&gt;
&lt;h3 id=&quot;docker-health-check&quot;&gt;Docker Health Check&lt;/h3&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Nachdem die Services deployt sind machen wir uns erneut die Möglichkeit zunutze, den Health-Status der Anwendung manuell zu setzen. Wir setzen eine Service-Instanz auf &lt;em&gt;unhealthy&lt;/em&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;highlight&quot;&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;curl $(docker-machine ip node-3):8080/environment/health?status=false&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;admonitionblock caution&quot;&gt;
&lt;table&gt;
&lt;tr&gt;
&lt;td class=&quot;icon&quot;&gt;
&lt;div class=&quot;title&quot;&gt;Achtung&lt;/div&gt;
&lt;/td&gt;
&lt;td class=&quot;content&quot;&gt;
Achtung, wir setzen hier die Umgebungsvariablen von &lt;strong&gt;Node-3&lt;/strong&gt;. Es ist aber nicht definiert, welcher Container wirklich angesprochen wird. Das entscheidet Docker intern über den DNS-Server.
&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Docker Swarm überwacht ständig den Status der Services / Tasks im Cluster und re-scheduled Container wenn nötig.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Standardmäßig versucht Swarm &lt;strong&gt;dreimal&lt;/strong&gt; den Health-Check durchzuführen, nach dem dritten gescheiterten Versuch wird der Container neu gestartet.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;videoblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;iframe src=&quot;https://www.youtube.com/embed/H9OEvQULVnI?rel=0&quot; frameborder=&quot;0&quot; allowfullscreen&gt;&lt;/iframe&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Zusätzlich werden nur Container geroutet, die Healthy sind. Sobald ein Container &lt;em&gt;unhealthy&lt;/em&gt; ist und der Manager dies erkennt wird er nicht mehr angesprochen.&lt;/p&gt;
&lt;/div&gt;
&lt;hr&gt;
&lt;div class=&quot;sect3&quot;&gt;
&lt;h4 id=&quot;fazit&quot;&gt;Fazit&lt;/h4&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Speziell im Swarm machen die Container Health Checks Sinn, da Swarm Container nicht routet, die &lt;em&gt;unhealthy&lt;/em&gt; sind.
Die Verwendung ist &lt;em&gt;wie immer&lt;/em&gt; denkbar einfach und funktioniert erstaunlich stabil und gut.&lt;/p&gt;
&lt;/div&gt;
&lt;hr&gt;
&lt;/div&gt;
&lt;div class=&quot;sect3&quot;&gt;
&lt;h4 id=&quot;links&quot;&gt;Links&lt;/h4&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;&lt;a href=&quot;https://github.com/effective-docker/docker-healthcheck.git&quot;&gt;Sourcen&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;&lt;a href=&quot;https://docs.docker.com/engine/swarm/&quot;&gt;swarm mode&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;hr&gt;
&lt;/div&gt;
&lt;div class=&quot;sect3&quot;&gt;
&lt;h4 id=&quot;docker-training&quot;&gt;Docker Training&lt;/h4&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;&lt;strong&gt;Wollen Sie mehr erfahren?&lt;/strong&gt;
Ich biete &lt;a href=&quot;http://www.effectivetrainings.de/html/workshops/effective_docker_workshop.php&quot;&gt;Consulting / Training&lt;/a&gt; für Docker. Schauen Sie doch mal vorbei!&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</content><summary type="html">Docker Swarm Mode Health Checks


TLDR;



Die Sourcen sind unter : https://github.com/effective-docker/docker-healthcheck.git


Swarm Scheduler arbeitet mit den Container Health Checks


Nur healthy Container werden geroutet.


Nach drei fehlgeschlagenen Health-Checks wird ein Container neu gestartet (ggf. auch auf einem anderen Knoten)






Docker Swarm Mode

Im letzten Eintrag haben wir uns mit Health Checks in Containern beschäftigt. Das alleine ist schon eine sehr wichtige Funktionalität, entwickelt ihr Potential allerdings erst in Zusammenarbeit mit einem Scheduler der das aktiv unterstützt. In diesem Artikel konzentrieren wir uns auf Docker Swarm im Swarm Mode (ab 1.12)</summary></entry><entry><title type="html">Docker Health Checks</title><link href="http://effective-docker.github.io/docker-healthchecks/" rel="alternate" type="text/html" title="Docker Health Checks" /><published>2017-01-03T00:00:00+00:00</published><updated>2017-01-03T00:00:00+00:00</updated><id>http://effective-docker.github.io/docker-healthchecks</id><content type="html" xml:base="http://effective-docker.github.io/docker-healthchecks/">&lt;div class=&quot;sect1&quot;&gt;
&lt;h2 id=&quot;docker-health-checks&quot;&gt;Docker Health Checks&lt;/h2&gt;
&lt;div class=&quot;sectionbody&quot;&gt;
&lt;div class=&quot;sect2&quot;&gt;
&lt;h3 id=&quot;tldr&quot;&gt;TLDR;&lt;/h3&gt;
&lt;div class=&quot;ulist&quot;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Die Sourcen sind unter : &lt;a href=&quot;https://github.com/effective-docker/docker-healthcheck.git&quot; class=&quot;bare&quot;&gt;https://github.com/effective-docker/docker-healthcheck.git&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Seit Docker 1.12 gibt es die Möglichkeit, Health-Checks für Container zu definieren&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Health-Checks sind vor allem zusammen mit Swarm hochinteressant: &lt;a href=&quot;https://docs.docker.com/engine/reference/builder/#/healthcheck&quot; class=&quot;bare&quot;&gt;https://docs.docker.com/engine/reference/builder/#/healthcheck&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;hr&gt;
&lt;/div&gt;
&lt;div class=&quot;sect2&quot;&gt;
&lt;h3 id=&quot;docker-container-health-checks&quot;&gt;Docker Container Health Checks&lt;/h3&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Anwendungen zu deployen ist &lt;em&gt;einfach&lt;/em&gt;, und Docker Container zu starten ist noch &lt;em&gt;einfacher&lt;/em&gt;.
 Ein einfaches &lt;em&gt;docker run&lt;/em&gt; und schon sind wir live. Das funktioniert
 auch eine ganze Zeit bis zum ersten Problem - sei es nun eine &lt;em&gt;Lastspitze&lt;/em&gt;, ein &lt;em&gt;Bug&lt;/em&gt;, ein Amoklaufender Prozess oder einfach ein &lt;em&gt;temporäres&lt;/em&gt; Netzwerkproblem.
 Die Anwendung ist nicht erreichbar, unsere &lt;em&gt;E-Commerce&lt;/em&gt;-Plattform ist für die Kunden nichts weiter als eine &lt;em&gt;500 - Wir arbeiten an einer Lösung&lt;/em&gt; und bis wir diese gefunden haben ist die Bestellung meistens schon bei der Konkurrenz gelandet.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Was machen wir also? Wir designen unser System so sicher und &lt;em&gt;gut&lt;/em&gt;, dass einfach keine Fehler auftreten? Das klingt verlockend, ist aber schlichtweg nicht möglich und sogar gefährlich, da wir uns dann in falscher Sicherheit wiegen. Wenn dann doch ein Problem auftritt sind wir nicht dafür gewappnet.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;admonitionblock tip&quot;&gt;
&lt;table&gt;
&lt;tr&gt;
&lt;td class=&quot;icon&quot;&gt;
&lt;div class=&quot;title&quot;&gt;Tipp&lt;/div&gt;
&lt;/td&gt;
&lt;td class=&quot;content&quot;&gt;
Besser ist es, die Anwendung gleich von Anfang so zu bauen dass Fehler akzeptiert werden und die Anwendung entsprechend darauf reagiert. &lt;strong&gt;Resilient Software&lt;/strong&gt; ist hier das wichtige Stichwort.
&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;hr&gt;
&lt;/div&gt;
&lt;div class=&quot;sect2&quot;&gt;
&lt;h3 id=&quot;beispielanwendung&quot;&gt;Beispielanwendung&lt;/h3&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Die Anwendung ist eine Spring Boot Anwendung mit &lt;a href=&quot;https://docs.spring.io/spring-boot/docs/current-SNAPSHOT/reference/htmlsingle/#production-ready&quot;&gt;Actuator&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;admonitionblock important&quot;&gt;
&lt;table&gt;
&lt;tr&gt;
&lt;td class=&quot;icon&quot;&gt;
&lt;div class=&quot;title&quot;&gt;Wichtig&lt;/div&gt;
&lt;/td&gt;
&lt;td class=&quot;content&quot;&gt;
Spring Boot Actuator bietet eine ganze Menge &lt;em&gt;Endpoints&lt;/em&gt; um den Zustand der Anwendung zu überwachen. Die Anwendung gibt beispielsweise über den Endpunkt &quot;/blog/health&quot; den Status zurück, ob sie &lt;em&gt;healthy&lt;/em&gt; ist. Healthy ist natürlich abhängig davon ob die verwendeten Upstream Services und die Infrastruktur-Komponenten verfügbar sind. Beispielsweise sollte die Anwendung nur &lt;em&gt;healthy&lt;/em&gt; sein, wenn eine verwendete Datenbank vorhanden ist.
&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Als nächstes starten wir die Anwendung.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;highlight&quot;&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;docker run -d --rm -p 8080:8080 effectivetrainings/docker-health&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Nach kurzer Zeit können wir über einen &lt;em&gt;cURL&lt;/em&gt; die &lt;em&gt;Healthyness&lt;/em&gt; der Anwendung abfragen.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;highlight&quot;&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;{
&quot;status&quot;:&quot;UP&quot;,
&quot;static&quot;:{&quot;status&quot;:&quot;UP&quot;},
&quot;diskSpace&quot;: {&quot;status&quot;:&quot;UP&quot;,&quot;total&quot;:67371577344,&quot;free&quot;:61355114496,&quot;threshold&quot;:10485760}
}&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Hier sehen wir die &lt;em&gt;HealthChecks&lt;/em&gt; der Anwendung. Selbst geschrieben ist der Static-Health-Check, mit dem die Anwendung einfach statisch in einen Healthy- oder Unhealthy-Zustand gesetzt werden kann.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;highlight&quot;&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;curl &quot;http://localhost:8080/environment/health?status=false&quot;

curl &quot;http://localhost:8080/health&quot;
{
    &quot;status&quot;: &quot;DOWN&quot;,
    &quot;static&quot;:{&quot;status&quot;:&quot;DOWN&quot;},
    &quot;diskSpace&quot;:{&quot;status&quot;:&quot;UP&quot;,&quot;total&quot;:67371577344,&quot;free&quot;:61354893312,threshold&quot;:10485760}
}&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Das Problem ist, der Container ist per Definition bisher immer noch gesund, obwohl die Anwendung vielleicht nicht mal antwortet. Die &lt;em&gt;Docker Engine&lt;/em&gt; weiß nichts vom Health-Status der Anwendung.
Der Container selbst hat &lt;em&gt;bis jetzt&lt;/em&gt; noch keinen Health-State.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Damit die Engine auf eine Änderung im Health-Status reagieren kann muss der Container selbst auch wissen, ob er Healthy ist oder nicht. Und genau hier kommen die neuen Health-Checks ins Spiel.&lt;/p&gt;
&lt;/div&gt;
&lt;hr&gt;
&lt;/div&gt;
&lt;div class=&quot;sect2&quot;&gt;
&lt;h3 id=&quot;docker-health-check&quot;&gt;Docker Health Check&lt;/h3&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Health Checks sind essentiell für die Anwendung - sowohl für das Monitoring, den Betrieb als auch für beispielsweise &lt;em&gt;Service Discovery&lt;/em&gt; in verteilten Umgebungen.
Dabei kann sich ein Health-Check ganz unterschiedlich gestalten, beispielsweise kann es für eine Oracle ein einfaches SQL Statement sein wie &lt;em&gt;select count from dual&lt;/em&gt;, ein HTTP-Status Code eines Actuator-Endpoints oder ein bash-script das nur prüft, ob ein bestimmter Prozess noch lebt.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Für jeden Container kann separat definiert werden, wie ein Health-Check ausgeführt werden kann. Für die Überwachung der Spring-Boot Anwendung beispielsweise bietet sich die Abfrage des &lt;em&gt;Health&lt;/em&gt;-Endpoint mittels &lt;em&gt;cURL&lt;/em&gt; an.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Für den Health-Check sind folgende Parameter für &lt;em&gt;docker run&lt;/em&gt; hinzugekommen. Analog könnten die Health-Checks im Dockerfile definiert werden.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;highlight&quot;&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;--health-cmd string   &lt;b class=&quot;conum&quot;&gt;(1)&lt;/b&gt;
--health-interval duration  (default 0s) &lt;b class=&quot;conum&quot;&gt;(2)&lt;/b&gt;
--health-retries int &lt;b class=&quot;conum&quot;&gt;(3)&lt;/b&gt;
--health-timeout duration (default 0s) &lt;b class=&quot;conum&quot;&gt;(4)&lt;/b&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;colist arabic&quot;&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Kommando für den Health-Check (Bash, Python..)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Zeit zwischen Health-Checks, standardmäßig alle 30  sekunden.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Retries bevor ein Container als &lt;em&gt;unhealthy&lt;/em&gt; deklariert wird&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Timeout für den Health-Check&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Ein einfacher Health-Check für die Spring-Boot Anwendung wäre beispielsweise folgender &lt;em&gt;cURL&lt;/em&gt;-Aufruf.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;admonitionblock tip&quot;&gt;
&lt;table&gt;
&lt;tr&gt;
&lt;td class=&quot;icon&quot;&gt;
&lt;div class=&quot;title&quot;&gt;Tipp&lt;/div&gt;
&lt;/td&gt;
&lt;td class=&quot;content&quot;&gt;
Ein Health-Check liefert einen boolschen Wert - 0 oder 1. 0 &amp;#8658; healthy, 1 &amp;#8658; unhealthy.
&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;highlight&quot;&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;--health-cmd curl -f http://localhost:8080/health | exit 1 &lt;b class=&quot;conum&quot;&gt;(1)&lt;/b&gt;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;colist arabic&quot;&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Mit &lt;em&gt;curl -f&lt;/em&gt; zwingt curl, den Fehlercode 1 im Falle eines HTTP-Errors zurückzuliefern, andernfalls den Code 0.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Starten wir den Container mit aktiviertem Health-Check.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;highlight&quot;&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;docker run -p 8080:8080 -d --name health-check --rm --health-cmd &quot;curl -f http://localhost:8080/health || exit 1&quot; effectivetrainings/docker-health&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Die Instruktion im Dockerfile wäre analog.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;highlight&quot;&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;HEALTHCHECK CMD curl -f http://localhost:8080/health || exit 1;&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;admonitionblock caution&quot;&gt;
&lt;table&gt;
&lt;tr&gt;
&lt;td class=&quot;icon&quot;&gt;
&lt;div class=&quot;title&quot;&gt;Achtung&lt;/div&gt;
&lt;/td&gt;
&lt;td class=&quot;content&quot;&gt;
Achtung - der Health-Check wird im Container ausgeführt, nur der interne Container ist also wichtig - &lt;strong&gt;nicht&lt;/strong&gt; der gemappte.
&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Mit &lt;em&gt;docker inspect healthcheck&lt;/em&gt; sehen wir jetzt einen Health-Status für den Container.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;highlight&quot;&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;&quot;Health&quot;: {
    &quot;Status&quot;: &quot;starting&quot;,
    &quot;FailingStreak&quot;: 0,
    &quot;Log&quot;: []
}&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Parallel ist es recht spannend, sich den Docker Event Stream ausgeben zu lassen.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;highlight&quot;&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;docker events

2017-01-03T22:10:18.137182990+01:00 container exec_start: /bin/sh -c curl -f http://localhost:8080/health 1a2bfc354a3eb75c41e8822620c85b7920ba0ebb9103aa481b090da6ce137037 (image=effectivetrainings/docker-health, name=health-check)

2017-01-03T22:10:18.527115972+01:00 container health_status: healthy 1a2bfc354a3eb75c41e8822620c85b7920ba0ebb9103aa481b090da6ce137037 (image=effectivetrainings/docker-health, name=health-check)&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Was aber passiert jetzt, wenn wir den Container auf &lt;em&gt;unhealthy&lt;/em&gt; setzen? Je nach eingestelltem Interval dauert es jetzt kurz, bis die Engine das Problem entdeckt.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;listingblock&quot;&gt;
&lt;div class=&quot;content&quot;&gt;
&lt;pre class=&quot;highlight&quot;&gt;&lt;code class=&quot;language-bash&quot; data-lang=&quot;bash&quot;&gt;curl &quot;localhost:8080/environment/health?status=false&quot;

docker ps

CONTAINER ID        IMAGE                              COMMAND                CREATED             STATUS                     PORTS                    NAMES
1a2bfc354a3e        effectivetrainings/docker-health   &quot;java -jar /app.jar&quot;   3 minutes ago       Up 3 minutes (unhealthy)   0.0.0.0:8080-&amp;gt;8080/tcp   health-check&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Ein Scheduler wie Docker Swarm könnte jetzt beispielsweise den Container einfach neustarten, &lt;em&gt;in der Hoffnung&lt;/em&gt;, dass das hilft.&lt;/p&gt;
&lt;/div&gt;
&lt;hr&gt;
&lt;div class=&quot;sect3&quot;&gt;
&lt;h4 id=&quot;fazit&quot;&gt;Fazit&lt;/h4&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Mit Container-Health Checks können relativ einfach Checks implementiert werden, die einen Scheduler unterstützen können die richtigen Entscheidungen zu treffen.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;ulist&quot;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Welcher Container wird jetzt neugestartet?&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Wohin soll deployt werden&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Docker Swarm beispielsweise macht sich den Health-Check zu Nutze und routet nur Requests zu Containern, die &lt;em&gt;healthy&lt;/em&gt; sind. Außerdem versucht Swarm, Container neu zu deployen, wenn Sie in den Status &lt;em&gt;unhealthy&lt;/em&gt; wechseln.&lt;/p&gt;
&lt;/div&gt;
&lt;hr&gt;
&lt;/div&gt;
&lt;div class=&quot;sect3&quot;&gt;
&lt;h4 id=&quot;links&quot;&gt;Links&lt;/h4&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;&lt;a href=&quot;https://github.com/effective-docker/docker-healthcheck.git&quot;&gt;Sourcen&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;&lt;a href=&quot;http://www.effectivetrainings.de/html/workshops/effective_docker_workshop.php&quot;&gt;Effecive Dockerschulung&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;Schöner NewRelic &lt;a href=&quot;https://blog.newrelic.com/2016/08/24/docker-health-check-instruction/&quot;&gt;Post&lt;/a&gt; zum Thema&lt;/p&gt;
&lt;/div&gt;
&lt;hr&gt;
&lt;/div&gt;
&lt;div class=&quot;sect3&quot;&gt;
&lt;h4 id=&quot;docker-training&quot;&gt;Docker Training&lt;/h4&gt;
&lt;div class=&quot;paragraph&quot;&gt;
&lt;p&gt;&lt;strong&gt;Wollen Sie mehr erfahren?&lt;/strong&gt;
Ich biete &lt;a href=&quot;http://www.effectivetrainings.de/html/workshops/effective_docker_workshop.php&quot;&gt;Consulting / Training&lt;/a&gt; für Docker. Schauen Sie doch mal vorbei!&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;</content><summary type="html">Docker Health Checks


TLDR;



Die Sourcen sind unter : https://github.com/effective-docker/docker-healthcheck.git


Seit Docker 1.12 gibt es die Möglichkeit, Health-Checks für Container zu definieren


Health-Checks sind vor allem zusammen mit Swarm hochinteressant: https://docs.docker.com/engine/reference/builder/#/healthcheck






Docker Container Health Checks

Anwendungen zu deployen ist einfach, und Docker Container zu starten ist noch einfacher.
 Ein einfaches docker run und schon sind wir live. Das funktioniert
 auch eine ganze Zeit bis zum ersten Problem - sei es nun eine Lastspitze, ein Bug, ein Amoklaufender Prozess oder einfach ein temporäres Netzwerkproblem.
 Die Anwendung ist nicht erreichbar, unsere E-Commerce-Plattform ist für die Kunden nichts weiter als eine 500 - Wir arbeiten an einer Lösung und bis wir diese gefunden haben ist die Bestellung meistens schon bei der Konkurrenz gelandet.</summary></entry></feed>
